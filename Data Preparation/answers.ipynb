{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies.\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import gensim\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load clue data file.\n",
    "clueDf = pd.read_csv(\"clueClustered.csv\",encoding=\"utf8\",index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SpaCy model. To download, run python -m spacy download en_core_web_lg.\n",
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As an input into the Doc2Vec model, we look to use the same preprocessing as the clustering process.\n",
    "# However, some answers consist solely of stop words. This is fine for clustering as the document is large,\n",
    "# but for answer matching we need that original data. Thus we process the category and clue, but keep the\n",
    "# answer as is (regardless, Doc2Vec doesn't need lemmatized input data).\n",
    "clueDf[\"inputRaw\"] = clueDf['category'] + ' ' + clueDf['clue']\n",
    "texts = []\n",
    "for doc in clueDf['inputRaw']:\n",
    "    docRaw = nlp(doc)\n",
    "    docProcessed = []\n",
    "    for token in docRaw:\n",
    "        if not token.is_stop and token.pos_ not in [\"PUNCT\",\"PART\",\"CONJ\",\"CCONJ\", \"SPACE\"]:\n",
    "            docProcessed.append(token.lemma_)\n",
    "    texts.append(\" \".join(docProcessed))\n",
    "clueDf['inputProcessed'] = texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build final input column, drop intermediate columns.\n",
    "clueDf['input'] = clueDf['inputProcessed'] + ' ' + clueDf['answer']\n",
    "clueDf.drop(columns=[\"inputRaw\",\"inputProcessed\"],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build gensim corpus\n",
    "corpus = []\n",
    "for i, doc in enumerate(clueDf['input']):\n",
    "    tokens = gensim.utils.simple_preprocess(doc,min_len=1,max_len=99)\n",
    "    corpus.append(gensim.models.doc2vec.TaggedDocument(tokens,[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Doc2Vec model. Most of the parameters are rather arbitrary, as there is not\n",
    "# a concrete way of quantifying performance in this use case (finding appropriate near-miss answers).\n",
    "model = gensim.models.doc2vec.Doc2Vec(vector_size=256,dm=0,epochs=25,min_count=1,window=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the Doc2Vec model.\n",
    "model.build_vocab(corpus)\n",
    "model.train(corpus, total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before building the near-miss answer set, we want to ensure we are not choosing duplicates.\n",
    "# This is a slightly modified processing procedure, which removes all symbols and stopwords, sets to lowercase,\n",
    "# and does not lemmatize (as the same word can have different lemmas based on capitalization).\n",
    "def process(strr):\n",
    "    strr = re.sub(r'\\W+',\" \",strr,re.UNICODE)\n",
    "    docRaw = nlp(strr)\n",
    "    docProcessed = []\n",
    "    for token in docRaw:\n",
    "        if not token.is_stop and token.pos_ not in [\"PUNCT\",\"PART\",\"CONJ\",\"CCONJ\",\"SPACE\"]:\n",
    "            docProcessed.append(token.text.lower())\n",
    "    return \" \".join(docProcessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spaces are also added before and after the processed text as \"in\" will be used to determine duplicates,\n",
    "# and we do not want to disqualify answers based on substring matching. These values will be used many times\n",
    "# in the near-miss answer building process, so these columns are built in advance to minimize process function calls.\n",
    "processedClueList = []\n",
    "processedAnswerList = []\n",
    "for index in range(len(clueDf)):\n",
    "    processedClueList.append(\" \"+process(clueDf.loc[index]['clue'])+\" \")\n",
    "    processedAnswerList.append(\" \"+process(clueDf.loc[index]['answer'])+\" \")\n",
    "clueDf['processedClue'] = processedClueList\n",
    "clueDf['processedAnswer'] = processedAnswerList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the list of near-miss answers to each clue.\n",
    "matchesList = [[f\"answer{i}\" for i in range(1,12)]]\n",
    "for index in range(len(gameDf)):\n",
    "    processedClue = gameDf.loc[index]['processedClue']\n",
    "    processedAnswer = gameDf.loc[index]['processedAnswer']\n",
    "    matches = [gameDf.loc[index]['answer']]\n",
    "    processedMatches = [processedAnswer]\n",
    "    # First find the 100 most similar documents to the document itself. It is possible that we do not find 5 near misses in this list, but doesn't happen in practice.\n",
    "    for row in model.docvecs.most_similar([model.infer_vector(corpus[index].words,epochs=50)],topn=100):\n",
    "        # Find the proposed near-miss answer and its processed equivalent.\n",
    "        candidate = gameDf.loc[row[0]]['answer']\n",
    "        if len(processedMatches) < 6:\n",
    "            processedCandidate = gameDf.loc[row[0]]['processedAnswer']\n",
    "            # Ensure that the processed near-miss answer does not exist within the processed clue or answer and vice versa.\n",
    "            if processedCandidate not in processedClue and sum([1 if processedCandidate in processedMatch else 0 for processedMatch in processedMatches])==0 and sum([1 if processedMatch in processedCandidate else 0 for processedMatch in processedMatches])==0:\n",
    "                matches.append(candidate)\n",
    "                processedMatches.append(processedCandidate)\n",
    "    # Repeat the process with the 100 most similar documents to just the answer (such that the emphasis is placed on the structure of the answer as opposed to the clue's meaning).\n",
    "    for row in model.docvecs.most_similar([model.infer_vector(gensim.utils.simple_preprocess(gameDf.loc[index]['answer'],min_len=1,max_len=99),epochs=50)],topn=100):\n",
    "        candidate = gameDf.loc[row[0]]['answer']\n",
    "        if len(processedMatches) < 11:\n",
    "            processedCandidate = gameDf.loc[row[0]]['processedAnswer']\n",
    "            if processedCandidate not in processedClue and sum([1 if processedCandidate in processedMatch else 0 for processedMatch in processedMatches])==0 and sum([1 if processedMatch in processedCandidate else 0 for processedMatch in processedMatches])==0:\n",
    "                matches.append(candidate)\n",
    "                processedMatches.append(processedCandidate)   \n",
    "    # This process will break if the clue is a list of answers for contestants to choose from. I suppose the process can be repeated without \"processedCandidate not in processedClue\",\n",
    "    # however that greatly increases the occurence of duplicates.\n",
    "    # Lastly, shuffle the near-miss answers.\n",
    "    matchesList.append([matches[i] for i in [0,1,6,2,7,3,8,4,9,5,10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert list of lists to dataframe, and then merge with clue dataframe.\n",
    "colNames = matchesList.pop(0)\n",
    "answerDf = pd.DataFrame(matchesList,columns=colNames)\n",
    "clueDf = clueDf.merge(answerDf,left_index=True,right_index=True).drop(columns=[\"answer\",\"input\",\"processedClue\",\"processedAnswer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge clues and metadata for one large file for further manual investigation, also to prepare for normalization.ipynb\n",
    "metadataDf = pd.read_csv(\"metadata.csv\",encoding=\"utf8\",index_col=0)\n",
    "clueDf = clueDf.merge(metadataDf,on=\"filename\")\n",
    "clueDf.to_csv(\"clueAnswers.csv\")"
   ]
  }
 ]
}